# Convolutional Neural Networks with Keras plus p5

## Examples
* [p5 and flask](https://github.com/shiffman/NOC-S17-2-Intelligence-Learning/tree/master/week5-cnn-tensorflow/01_simple_flask_p5)
* [Visualizing CNN Steps with p5](https://github.com/shiffman/NOC-S17-2-Intelligence-Learning/tree/master/week5-cnn-tensorflow/00_p5_convolution/) (in progress)
* [CNN1: training and testing digits](https://github.com/shiffman/NOC-S17-2-Intelligence-Learning/tree/master/week5-cnn-tensorflow/02a_cnn_keras)
* [CNN2: classifying digit drawn with p5](https://github.com/shiffman/NOC-S17-2-Intelligence-Learning/tree/master/week5-cnn-tensorflow/02b_cnn_flask_p5)
* [CNN3: classifying images from p5 using pre-trained RESNET-50 model](https://github.com/shiffman/NOC-S17-2-Intelligence-Learning/tree/master/week5-cnn-tensorflow/03_resnet50_flask_p5)

## Convolutional Neural Networks
* [An Intuitive Explanation of Convolutional Neural Networks](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/) by Ujjwal Karn
* [Original 1998 "LetNet5" paper: "Gradient-Based Learning Applied to Document Recognition"](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) by Y. Lecun, L. Bottou, Y. Bengio, P. Haffner
* [Online 3D Visualization of a Convolutional Network trained on MNIST](http://scs.ryerson.ca/~aharley/vis/conv/flat.html) by Adam Harley.
* [A friendly introduction to Convolutional Neural Networks and Image Recognition](https://www.youtube.com/watch?v=2-Ol7ZB0MmU&feature=youtu.be), video tutorial by Luis Serrano
* [Siraj's CNN video](https://www.youtube.com/watch?v=cAICT4Al5Ow&feature=youtu.be), [code on github](https://github.com/llSourcell/how_to_make_an_image_classifier)

### Steps
1. Convolution, see: [Convolution Matrix](https://docs.gimp.org/en/plug-in-convmatrix.html) from GIMP documentation.
2. ReLU (aka "Rectified Linear Unit"): A non-linear activation function that turns all negative values into zero.
3. Pooling: reduces the resolution / dimensionality of each feature map generated by the convolution. (see "equivarient" below).
4. Classification (Fully-Connected Network)

### Terminology
  * [filter (aka kernel)](https://en.wikipedia.org/wiki/Kernel_(image_processing))
  * feature map
  * equivarient: refers to the scale independent nature of the features, allowing objects to be detected in the image at any size / location.
  * [softmax](http://cs231n.github.io/linear-classify/#softmax): an activation function for the final output layer that squashes all values to between 0 and 1 (and adding up to 1). This is perfect for probabilistic outputs like image classifcation.
  * [one-hot encoding](https://en.wikipedia.org/wiki/One-hot): This is a technique that stores categorical features for classification in binary format. For example, cat: `001`, dog: `010`, turtle: `100`.
  * [loss](https://github.com/shiffman/NOC-S17-2-Intelligence-Learning/wiki/Glossary:-Machine-learning#loss-function): A loss (or cost) function (also known as a cost function) quantifies how the performance of a model on the training set. For example "mean squared error" sums the squared differences between predicted and actual values. See below for loss functions available in keras.

### CNN Parameters
* filter size
* depth: number of filters per convolution layer
* stride: number of pixels the filter "sliders over" (i.e. are any pixels skipped to reduce)
* dropout: a technique to help prevent overfitting: randomly sets some input units to 0 (effectively ignoring them) during each training step.
* flatten: refers to taking a multi-dimensional output and "flattening" it into one dimension. For example, a 2D matrix of pixels converted into a 1D array of pixels.

### Examples of Convolutional Network Architectures
* [VGGNet](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)
* [ResNets](https://arxiv.org/abs/1512.03385)
* [DenseNet](https://arxiv.org/abs/1608.06993), [Github](https://github.com/liuzhuang13/DenseNet)

## Tools, frameworks, libraries for this week

### Python
* [Follow these Environment Setup](https://github.com/shiffman/NOC-S17-2-Intelligence-Learning/wiki/Python-Environment-Setup) instructions using [Miniconda](https://conda.io/miniconda.html), [Python 3](https://www.python.org/), and [tensorflow](https://www.tensorflow.org/).
* [Python Tutorial / Cheatsheet](https://www.stavros.io/tutorials/python/) by Stavros Korokithakis.

### Flask
* [Flask: a python "microframework" for web applications](http://flask.pocoo.org/)
* `pip install Flask`
* `python server.py` [flask + p5 example](https://github.com/shiffman/NOC-S17-2-Intelligence-Learning/tree/master/week5-cnn-rnn-tensorflow/01_simple_flask_p5)

### Jupyter Project
* [Jupyter Notebook](http://jupyter.org/) is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text.
* I'm using Jupyter notebooks to demonstrate and experiment with training machine learning models using keras/tensorflow. After the model is complete, I switch to running the flask server from the command line to communicate with a p5 sketch.

### Numpy
* [Numpy](http://www.numpy.org/) is a scientific computing package for Python. We will be making use of its "linear algebra" features for storing all inputs and outputs to the machine learning systems as "matrices".
* [Numpy Quickstart tutorial](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)
* Some numpy functions I am using
  * `dot()`: [docs](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html)
  * `reshape()`: [docs](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html)
  * `expand_dims()`: [docs](https://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html)

### Keras / Tensorflow
* [Tensorflow](https://www.tensorflow.org/) is an open-source library for machine learning. [github](https://github.com/tensorflow/)
* [Keras](https://keras.io/) Keras is a higher-level machine learning API that runs on top of TensorFlow. Keras allows for easy and fast prototyping and supports both convolutional and recurrent networks.

### Things we are using in Keras
* [Sequential](https://keras.io/models/sequential/): a linear stack of layers. This is the architecture of your model! Look at Jyo Pari's [tutorial](https://www.youtube.com/watch?v=__MVW-TCYjk) using the Sequential model to train the XOR rule!
* [Conv2D](https://keras.io/layers/convolutional/): a 2D convolutional layer
* [Dense](https://keras.io/layers/core/): a "regular" fully-connected neural network layer
* [Loss functions](https://keras.io/losses/): keras includes several options for loss functions. For categorical classification scenarios using softmax, you'll typically see a function called "categorical_crossentropy" used.
* [Optimizers](https://keras.io/optimizers/): This refers to the "gradient descent" algorithm used. In my examples you'll see "RMSProp" (Root Mean Square Propogation) which is a method that adjusts the learning rate for each parameter according to the gradient magnitudes.
* [Metrics](https://keras.io/metrics/): This refers to the function that evaluates the performance of your model.
* [Saving and Loading a Keras Model](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model)

### Some additional image stuff
* [base64 encoding and decoding](https://developer.mozilla.org/en-US/docs/Web/API/WindowBase64/Base64_encoding_and_decoding) with [toDataURL()](https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/toDataURL)
* [PIL](https://pypi.python.org/pypi/PIL) (Python Imaging Library)
